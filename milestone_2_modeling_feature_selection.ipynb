{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression, ElasticNet, Ridge, Lasso\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor, PassiveAggressiveRegressor, Lars\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(\"data\\\\milestone_data_X_train.pkl\")\n",
    "y_train = pd.read_pickle(\"data\\\\milestone_data_y_train.pkl\")\n",
    "X_test = pd.read_pickle(\"data\\\\milestone_data_X_test.pkl\")\n",
    "y_test = pd.read_pickle(\"data\\\\milestone_data_y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_pickle(\"data\\\\milestone_data_X_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (221122, 1095)\n",
      "y_train shape (221122,)\n",
      "X_test shape (32257, 1095)\n",
      "y_test shape (32257,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Check there are no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_NaN = X_train.isnull()\n",
    "col_has_NaN = is_NaN.any(axis=0)\n",
    "col_has_NaN = col_has_NaN.loc[col_has_NaN==True].index.to_list()\n",
    "col_has_NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = X_train._get_numeric_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that contain infinity or negative infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volume_adi', 'trend_vortex_ind_pos', 'trend_vortex_ind_neg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_has_inf = X_train_numeric.columns.to_series()[np.isinf(X_train_numeric).any()].to_list()\n",
    "col_has_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = X_train_numeric.drop(col_has_inf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train_numeric.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesianRidge(compute_score=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = BayesianRidge(compute_score=True)\n",
    "model.fit(X_train_numeric, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_train = model.predict(X_train[cols])\n",
    "y_pred_test = model.predict(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that this will run on the validation data - we won't score against the validation data until once at the very end\n",
    "y_pred_val = model.predict(X_val[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring\n",
    "First using a typical regression metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the training score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05871998787118553"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the test score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06651413809583322"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test score is slightly worse than the train score but the difference does not seem huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now converting to a classification metric. We will test for precision. We will first establish a benchmark by calculating what our precision would be if we simply predict that everything goes up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_clf_pred(pred, threshold=1):\n",
    "    pred_clf = (pred > threshold) * 1 # multiply by 1 to change to binary from True / False\n",
    "    \n",
    "    return pred_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_clf = pred_to_clf_pred(y_train, threshold=1)\n",
    "y_test_clf = pred_to_clf_pred(y_test, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_up_train = [1] * len(y_train_clf)\n",
    "y_all_up_test = [1] * len(y_test_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_precision_train_score = precision_score(y_train_clf, y_all_up_train)\n",
    "benchmark_precision_test_score = precision_score(y_test_clf, y_all_up_test)\n",
    "benchmark_return_train = np.mean(y_train) - 1\n",
    "benchmark_return_test = np.mean(y_test) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_benchmarks():\n",
    "    print(\"Benchmark figures over 20 day prediction horizon:\")\n",
    "    print(\"benchmark precision train:\", round(benchmark_precision_train_score,5))\n",
    "    print(\"benchmark precision test:\", round(benchmark_precision_test_score,5))\n",
    "    print(\"benchmark return train:\", round(benchmark_return_train,5))\n",
    "    print(\"benchmark return test:\", round(benchmark_return_test,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark figures over 20 day prediction horizon:\n",
      "benchmark precision train: 0.53814\n",
      "benchmark precision test: 0.5835\n",
      "benchmark return train: 0.005\n",
      "benchmark return test: 0.02214\n"
     ]
    }
   ],
   "source": [
    "print_benchmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the benchmark precision if we predict everything goes up. Now we will test the precision of our model. We can see that market conditions in the test period were noticeably different to the training period as stocks were going up a lot more frequently over 20 day trading horizons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_clf_train = pred_to_clf_pred(y_pred_train, threshold=1)\n",
    "#y_pred_clf = pred_to_clf_pred(y_pred_test, threshold=1) #(y_pred_test > 1) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the precision score on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_precision(y, pred, percentile):\n",
    "    threshold = np.percentile(pred, percentile)\n",
    "    pred_clf = (pred > threshold) * 1\n",
    "    threshold_precision = precision_score(y, pred_clf)\n",
    "    \n",
    "    return round(threshold_precision,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_and_threshold_scoring(y, y_pred, percentile):\n",
    "    threshold = np.percentile(y_pred, percentile)\n",
    "    results = {}\n",
    "    y_clf = pred_to_clf_pred(y, threshold=1)\n",
    "    y_pred_clf = pred_to_clf_pred(y_pred, threshold=1)\n",
    "    results['default_precision'] = round(precision_score(y_clf, y_pred_clf),5)\n",
    "    results['default_return'] = round(np.mean(y[y_pred>1])-1,5)\n",
    "    results['threshold_precision'] = threshold_precision(y_clf, y_pred, percentile)\n",
    "    results['threshold_return'] = round(np.mean(y[y_pred>threshold])-1,5)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate model peformance on train and test using the metrics specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark figures over 20 day prediction horizon:\n",
      "benchmark precision train: 0.53814\n",
      "benchmark precision test: 0.5835\n",
      "benchmark return train: 0.005\n",
      "benchmark return test: 0.02214\n",
      "train: {'default_precision': 0.57186, 'default_return': 0.01559, 'threshold_precision': 0.70779, 'threshold_return': 0.08725}\n",
      "test:  {'default_precision': 0.57052, 'default_return': 0.01887, 'threshold_precision': 0.52821, 'threshold_return': 0.01978}\n"
     ]
    }
   ],
   "source": [
    "print_benchmarks()\n",
    "print(\"train:\",full_and_threshold_scoring(y_train,y_pred_train,95))\n",
    "print(\"test: \",full_and_threshold_scoring(y_test,y_pred_test,95))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Results\n",
    "Here we can see that in our training data we achieved an improvement over the benchmark for precision and return where we set the precision threshold to predict any stock with a prediction of the price going up to go up. When we made our threshold more restrictive, so that we only predicted the stock would go up for our 5% highest predictions, on our train data the precision and return vastly outperformed the benchmark.\n",
    "#### Test Results\n",
    "On the test data we did not beat the benchmark when we classified all predictions that a stock would go up as the stock would go up. When we only indicated the stock would go up for our highest 5% of predictions, our precision is even worse although the average return is slightly better than at the default threshold. Now we will need to use some supervised learning techniques to select features and try with different models to improve on this precision score and aim get it above the benchmark. The issue is likely to be partly overfitting and partly model drift as we saw from the benchmark precision the market conditions were very different in the test period to the training period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering Features\n",
    "Given the large number of features already generated and retrieved, it is not clear how much feature engineering will add. However, we will at least generate features that demonstrate when volume is above average as in the financial domain, price moves are widely thought to be more meaningful and likely to continue when accompanied by heavy volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['Volume_over_Volume_MA50'] = df['Volume'] / df['Volume_MA50']\n",
    "    df['Volume_over_Volume_MA200'] = df['Volume'] / df['Volume_MA200']\n",
    "    df['Volume_MA50_over_Volume_MA200'] = df['Volume_MA50'] / df['Volume_MA200']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = feature_engineering(X_train_numeric)\n",
    "X_test = feature_engineering(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "We saw in the earlier notebook that modeling with just a few features achieved better results than using all 1000+ features. Here we will start with a tiny number of features and iteratively try adding (& later dropping) features to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train_numeric.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['volatility_kcl', 'Open', 'High', 'Low', 'Volume', 'Volume_MA200', 'SR', 'ValueRank', 'MomentumRank', 'Price_to_Book_Latest', 'Sales_Growth_TTM_pct', 'volume_sma_em', 'volume_nvi', 'volume_vwap', 'volatility_bbhi', 'volatility_kcw', 'volatility_kchi', 'volatility_dch', 'trend_mass_index', 'trend_ichimoku_a', 'trend_psar_down', 'trend_stc', 'momentum_stoch_signal', 'momentum_kama', 'AROONOSC_14', 'MOM_40', 'ROC_60', 'ROCP_60', 'RSI_60', 'ROCR100_90', 'MACDEXT_macdhist_f3_s21_sig55', 'MACDEXT_macdhist_f8_s34_sig5', 'MACDEXT_macdhist_f8_s89_sig34', 'MACDEXT_macd_f34_s55_sig5', 'EPS_Growth_TTM_pct_NaN', 'Volume_over_Volume_MA50', 'ROE_TTM_pct', 'trend_vortex_ind_diff', 'PLUS_DI_3', 'AROONOSC_20', 'PLUS_DI_20', 'WILLR_40', 'AROONup_60', 'MACDEXT_macdhist_f2_s34_sig55', 'volume_cmf']\n",
    "selected_cols = ['SR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_return_test = 0.06424\n",
    "threshold_return_test = 0\n",
    "threshold_return_train = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(current_selection):\n",
    "        np.random.seed(0)\n",
    "        #model = RandomForestRegressor(max_depth=3, random_state=6, criterion=\"mse\", n_jobs=-1) #, min_impurity_decrease=0.01) # \n",
    "        #model = LinearRegression()\n",
    "        #model = MLPRegressor(random_state=7)\n",
    "        model = PassiveAggressiveRegressor()\n",
    "        model.fit(X_train_numeric[current_selection], y_train)\n",
    "        # make the predictions\n",
    "        y_pred_fundamental_train = model.predict(X_train_numeric[current_selection])\n",
    "        y_pred_fundamental_test = model.predict(X_test[current_selection])\n",
    "        # convert to classification\n",
    "        y_pred_clf_fundamental_train = pred_to_clf_pred(y_pred_fundamental_train, threshold=1)\n",
    "        y_pred_clf_fundamental_test = pred_to_clf_pred(y_pred_fundamental_test, threshold=1)\n",
    "        train_scores = full_and_threshold_scoring(y_train,y_pred_fundamental_train,95)\n",
    "        test_scores = full_and_threshold_scoring(y_test,y_pred_fundamental_test,95)\n",
    "        #print(c, test_scores['threshold_return'] )\n",
    "        \n",
    "        return train_scores, test_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1092/1092 [10:09<00:00,  1.79it/s]\n",
      "  0%|                                                                                         | 0/1092 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train return at threshold 0.05668 test return at threshold 0.05113\n",
      "###############################################################\n",
      "['Open', 'Adj. close**', 'volatility_bbm', 'trend_macd', 'PLUS_DM_10', 'MACDEXT_macdhist_f5_s8_sig34']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1092/1092 [10:56<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train return at threshold 0.05668 test return at threshold 0.05113\n",
      "###############################################################\n",
      "['Open', 'Adj. close**', 'volatility_bbm', 'trend_macd', 'PLUS_DM_10', 'MACDEXT_macdhist_f5_s8_sig34']\n",
      "early stopping no improvement\n",
      "Wall time: 21min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loop_best = 0\n",
    "for a in range(20): # the second loop gives a chance to drop features that were useful originally but are not useful with the latest best feature set   \n",
    "    for c in tqdm(cols):\n",
    "        current_selection = copy.deepcopy(selected_cols)\n",
    "        if c in current_selection and len(current_selection) > 1:\n",
    "            current_selection.remove(c)\n",
    "        else:\n",
    "            current_selection.append(c)\n",
    "            \n",
    "        train_scores, test_scores = run_model(current_selection)\n",
    "            \n",
    "        if test_scores['threshold_return'] > threshold_return_test and train_scores['threshold_return'] > threshold_return_train:\n",
    "            #print(\"improvement found\")\n",
    "            #print(current_selection)\n",
    "            threshold_return_test = test_scores['threshold_return']\n",
    "            threshold_return_train = train_scores['threshold_return']\n",
    "            selected_cols = copy.deepcopy(current_selection)\n",
    "            \n",
    "    print(\"train return at threshold\", threshold_return_train, \"test return at threshold\", threshold_return_test)\n",
    "    print(\"###############################################################\")\n",
    "    print(selected_cols)\n",
    "    \n",
    "    if loop_best==threshold_return_test:\n",
    "        print(\"early stopping no improvement\")\n",
    "        break\n",
    "    loop_best=threshold_return_test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores, test_scores = run_model(selected_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark figures over 20 day prediction horizon:\n",
      "benchmark precision train: 0.53814\n",
      "benchmark precision test: 0.5835\n",
      "benchmark return train: 0.005\n",
      "benchmark return test: 0.02214\n",
      "train scores: {'default_precision': 0.52807, 'default_return': 0.00672, 'threshold_precision': 0.60658, 'threshold_return': 0.05668}\n",
      "test scores: {'default_precision': 0.57331, 'default_return': 0.02748, 'threshold_precision': 0.52945, 'threshold_return': 0.05113}\n"
     ]
    }
   ],
   "source": [
    "print_benchmarks()\n",
    "print(\"train scores:\", train_scores)\n",
    "print(\"test scores:\", test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "Feature Selection and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
