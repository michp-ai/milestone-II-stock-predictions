{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression, ElasticNet, Ridge, Lasso, LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "from utils_milestone2 import get_numeric_non_infinite_cols, add_pca_cols, scale_train_test, pca_train_test, run_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Run_Feature_Selection = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(\"data\\\\milestone_data_X_train.pkl\")\n",
    "y_train = pd.read_pickle(\"data\\\\milestone_data_y_train.pkl\")\n",
    "X_test = pd.read_pickle(\"data\\\\milestone_data_X_test.pkl\")\n",
    "y_test = pd.read_pickle(\"data\\\\milestone_data_y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_pickle(\"data\\\\milestone_data_X_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (221122, 1095)\n",
      "y_train shape (221122,)\n",
      "X_test shape (32257, 1095)\n",
      "y_test shape (32257,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Check there are no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_NaN = X_train.isnull()\n",
    "col_has_NaN = is_NaN.any(axis=0)\n",
    "col_has_NaN = col_has_NaN.loc[col_has_NaN==True].index.to_list()\n",
    "col_has_NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = X_train._get_numeric_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that contain infinity or negative infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volume_adi', 'trend_vortex_ind_pos', 'trend_vortex_ind_neg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_has_inf = X_train_numeric.columns.to_series()[np.isinf(X_train_numeric).any()].to_list()\n",
    "col_has_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = X_train_numeric.drop(col_has_inf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train_numeric.columns.to_list()\n",
    "X_test_numeric = X_test[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring\n",
    "First using a typical regression metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now converting to a classification metric. We will test for precision. We will first establish a benchmark by calculating what our precision would be if we simply predict that everything goes up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_clf_pred(pred, threshold=1):\n",
    "    pred_clf = (pred > threshold) * 1 # multiply by 1 to change to binary from True / False\n",
    "    \n",
    "    return pred_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_clf = pred_to_clf_pred(y_train, threshold=1)\n",
    "y_test_clf = pred_to_clf_pred(y_test, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_up_train = [1] * len(y_train_clf)\n",
    "y_all_up_test = [1] * len(y_test_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_precision_train_score = precision_score(y_train_clf, y_all_up_train)\n",
    "benchmark_precision_test_score = precision_score(y_test_clf, y_all_up_test)\n",
    "benchmark_return_train = np.mean(y_train) - 1\n",
    "benchmark_return_test = np.mean(y_test) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_benchmarks():\n",
    "    print(\"Benchmark figures over 20 day prediction horizon:\")\n",
    "    print(\"benchmark precision train:\", round(benchmark_precision_train_score,5))\n",
    "    print(\"benchmark precision test:\", round(benchmark_precision_test_score,5))\n",
    "    print(\"benchmark return train:\", round(benchmark_return_train,5))\n",
    "    print(\"benchmark return test:\", round(benchmark_return_test,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark figures over 20 day prediction horizon:\n",
      "benchmark precision train: 0.53814\n",
      "benchmark precision test: 0.5835\n",
      "benchmark return train: 0.005\n",
      "benchmark return test: 0.02214\n"
     ]
    }
   ],
   "source": [
    "print_benchmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the benchmark precision if we predict everything goes up. Now we will test the precision of our model. We can see that market conditions in the test period were noticeably different to the training period as stocks were going up a lot more frequently over 20 day trading horizons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_clf_train = pred_to_clf_pred(y_pred_train, threshold=1)\n",
    "#y_pred_clf = pred_to_clf_pred(y_pred_test, threshold=1) #(y_pred_test > 1) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the precision score on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_precision(y, pred, percentile):\n",
    "    threshold = np.percentile(pred, percentile)\n",
    "    pred_clf = (pred > threshold) * 1\n",
    "    threshold_precision = precision_score(y, pred_clf)\n",
    "    \n",
    "    return round(threshold_precision,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def full_and_threshold_scoring(y, y_pred, percentile, model_type=\"regression\"):\n",
    "#     threshold = np.percentile(y_pred, percentile)\n",
    "#     results = {}\n",
    "#     threshold = 1\n",
    "#     if model_type==\"classification\":\n",
    "#         threshold = 0.5\n",
    "    \n",
    "#     y_clf = pred_to_clf_pred(y, threshold=threshold)\n",
    "#     y_pred_clf = pred_to_clf_pred(y_pred, threshold=threshold)\n",
    "#     if model_type==\"classification\":\n",
    "#         results['default_precision'] = round(precision_score(y_clf, y_pred_clf),5)\n",
    "#         #results['threshold_precision'] = threshold_precision(y, y_pred, percentile)    \n",
    "#     if model_type==\"regression\":\n",
    "#         results['default_precision'] = round(precision_score(y_clf, y_pred_clf),5)\n",
    "#         results['threshold_precision'] = threshold_precision(y_clf, y_pred, percentile)\n",
    "#         results['default_return'] = round(np.mean(y[y_pred>1])-1,5)\n",
    "#         results['threshold_return'] = round(np.mean(y[y_pred>threshold])-1,5)\n",
    "    \n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_and_threshold_scoring(y, y_pred, percentile):\n",
    "    threshold = np.percentile(y_pred, percentile)\n",
    "    results = {}\n",
    "    y_clf = pred_to_clf_pred(y, threshold=1)\n",
    "    y_pred_clf = pred_to_clf_pred(y_pred, threshold=1)\n",
    "    results['default_precision'] = round(precision_score(y_clf, y_pred_clf),5)\n",
    "    results['default_return'] = round(np.mean(y[y_pred>1])-1,5)\n",
    "    results['threshold_precision'] = threshold_precision(y_clf, y_pred, percentile)\n",
    "    results['threshold_return'] = round(np.mean(y[y_pred>threshold])-1,5)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate model peformance on train and test using the metrics specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark figures over 20 day prediction horizon:\n",
      "benchmark precision train: 0.53814\n",
      "benchmark precision test: 0.5835\n",
      "benchmark return train: 0.005\n",
      "benchmark return test: 0.02214\n"
     ]
    }
   ],
   "source": [
    "print_benchmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Results\n",
    "Here we can see that in our training data we achieved an improvement over the benchmark for precision and return where we set the precision threshold to predict any stock with a prediction of the price going up to go up. When we made our threshold more restrictive, so that we only predicted the stock would go up for our 5% highest predictions, on our train data the precision and return vastly outperformed the benchmark.\n",
    "#### Test Results\n",
    "On the test data we did not beat the benchmark when we classified all predictions that a stock would go up as the stock would go up. When we only indicated the stock would go up for our highest 5% of predictions, our precision is even worse although the average return is slightly better than at the default threshold. Now we will need to use some supervised learning techniques to select features and try with different models to improve on this precision score and aim get it above the benchmark. The issue is likely to be partly overfitting and partly model drift as we saw from the benchmark precision the market conditions were very different in the test period to the training period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering Features\n",
    "Given the large number of features already generated and retrieved, it is not clear how much feature engineering will add. However, we will at least generate features that demonstrate when volume is above average as in the financial domain, price moves are widely thought to be more meaningful and likely to continue when accompanied by heavy volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['Volume_over_Volume_MA50'] = df['Volume'] / df['Volume_MA50']\n",
    "    df['Volume_over_Volume_MA200'] = df['Volume'] / df['Volume_MA200']\n",
    "    df['Volume_MA50_over_Volume_MA200'] = df['Volume_MA50'] / df['Volume_MA200']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\.conda\\envs\\env2\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\micha\\.conda\\envs\\env2\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\micha\\.conda\\envs\\env2\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X_train_numeric = feature_engineering(X_train_numeric)\n",
    "X_test_numeric = feature_engineering(X_test_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_numeric_scaled, X_test_numeric_scaled = scale_train_test(X_train_numeric, X_test_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Explained 0.9994445216152267\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_pca, X_test_pca = pca_train_test(X_train_numeric_scaled, X_test_numeric_scaled, num_components=200, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_numeric_plus_pca = add_pca_cols(X_train_numeric, X_train_pca)\n",
    "X_test_numeric_plus_pca = add_pca_cols(X_test_numeric, X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "We saw in the earlier notebook that modeling with just a few features achieved better results than using all 1000+ features. Here we will start with a tiny number of features and iteratively try adding (& later dropping) features to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train_numeric_plus_pca.columns.to_list()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['SR', 'ROCE_TTM_pct', 'Price_to_FCF_TTM', 'MACDSIGNAL_55', 'trend_ema_slow', 'others_dlr']\n",
    "#selected_cols = ['SR', 'ROCE_TTM_pct', 'Price_to_FCF_TTM', 'MACDSIGNAL_55', 'trend_ema_slow', 'others_dlr', 'pca_199', 'pca_110', 'NATR_90', 'MACDEXT_macd_f34_s89_sig55', 'MACDEXT_macd_f21_s89_sig55', 'MACDEXT_macdsignal_f8_s89_sig55', 'MACDEXT_macdhist_f8_s89_sig5', 'MACDEXT_macd_f8_s89_sig5', 'MACDEXT_macdsignal_f8_s55_sig34', 'MACDEXT_macdhist_f3_s55_sig21', 'PLUS_DI_25', 'MACDEXT_macdsignal_f21_s89_sig8', 'MACDEXT_macdhist_f2_s21_sig8', 'ADOSC_f21_s89']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold_return_train = 0.07564\n",
    "#threshold_return_test = 0.06424\n",
    "default_precision_test = 0\n",
    "default_precision_train = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression()\n",
    "# y_train_clf = pred_to_clf_pred(y_train, threshold=1)\n",
    "# y_test_clf = pred_to_clf_pred(y_test, threshold=1)\n",
    "# model.fit(X_train_numeric_plus_pca[current_selection], y_train_clf)\n",
    "# # make the predictions\n",
    "# y_pred_fundamental_train = model.predict_proba(X_train_numeric_plus_pca[current_selection])[:,1]\n",
    "# y_pred_fundamental_test = model.predict_proba(X_test_numeric_plus_pca[current_selection])[:,1]\n",
    "# # convert to classification\n",
    "# y_pred_clf_fundamental_train = pred_to_clf_pred(y_pred_fundamental_train, threshold=0.5)\n",
    "# y_pred_clf_fundamental_test = pred_to_clf_pred(y_pred_fundamental_test, threshold=0.5)\n",
    "# print(y_pred_fundamental_train.shape)\n",
    "# print(y_train.shape)\n",
    "# train_scores = full_and_threshold_scoring(y_train,y_pred_fundamental_train,95,model_type=\"classification\")\n",
    "# test_scores = full_and_threshold_scoring(y_test,y_pred_fundamental_test,95,model_type=\"classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loop_best = 0\n",
    "if Run_Feature_Selection:\n",
    "    for a in range(20): # the second loop gives a chance to drop features that were useful originally but are not useful with the latest best feature set   \n",
    "        for c in tqdm(cols):\n",
    "            current_selection = copy.deepcopy(selected_cols)\n",
    "            if c in current_selection and len(current_selection) > 1:\n",
    "                current_selection = [x for x in current_selection if x!=c]#.remove(c)\n",
    "            else:\n",
    "                current_selection.append(c)\n",
    "\n",
    "            train_scores, test_scores = run_model(current_selection, X_train_numeric_plus_pca, X_test_numeric_plus_pca, y_train, y_test)\n",
    "\n",
    "            if test_scores['default_precision'] > default_precision_test and train_scores['default_precision'] > default_precision_train:\n",
    "                #print(\"improvement found\")\n",
    "                #print(current_selection)\n",
    "                default_precision_test = test_scores['default_precision']\n",
    "                default_precision_train = train_scores['default_precision']\n",
    "                selected_cols = copy.deepcopy(current_selection)\n",
    "\n",
    "        print(\"train precision at default\", default_precision_train, \"test precision at default\", default_precision_test)\n",
    "        print(\"##################################################################\")\n",
    "        print(selected_cols)\n",
    "\n",
    "        if loop_best==default_precision_test:\n",
    "            print(\"early stopping no improvement\")\n",
    "            break\n",
    "        loop_best=default_precision_test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores, test_scores = run_model(selected_cols, X_train_numeric_plus_pca, X_test_numeric_plus_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark figures over 20 day prediction horizon:\n",
      "benchmark precision train: 0.53814\n",
      "benchmark precision test: 0.5835\n",
      "benchmark return train: 0.005\n",
      "benchmark return test: 0.02214\n",
      "train scores: {'default_precision': 0.53753, 'default_return': 0.00564, 'threshold_precision': 0.60601, 'threshold_return': 0.0283}\n",
      "test scores: {'default_precision': 0.58484, 'default_return': 0.02402, 'threshold_precision': 0.6181, 'threshold_return': 0.03136}\n"
     ]
    }
   ],
   "source": [
    "print_benchmarks()\n",
    "print(\"train scores:\", train_scores)\n",
    "print(\"test scores:\", test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "Feature Selection and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
